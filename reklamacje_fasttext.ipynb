{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rozpoznawanie typów reklamacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładowanie danych z pliku xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datapath='/mnt/c/dev/reklamacje/'\n",
    "datafile='reklamacje_20181106_train.xlsx'\n",
    "dane_surowe=pd.read_excel(os.path.join(datapath,datafile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dane_surowe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_surowe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.DataFrame()\n",
    "input_data[['content','category']]=dane_surowe[['tresc_zgl','typ_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing data\n",
    "# remove duplicates\n",
    "input_data.drop_duplicates(inplace=True)\n",
    "# remove empty\n",
    "input_data=input_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates\n",
    "input_data[input_data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "załadowanie słowników tłumaczeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słownik synonimów / podmian\n",
    "\n",
    "podmiany=pd.read_excel(os.path.join(datapath,'roboczy_slownik_synonimow.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing of content text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(raw_texts,replacements):\n",
    "    \"\"\"\n",
    "    texts: np.Series containing strings to be preprocessed\n",
    "    replacements: pairs of what convert to what\n",
    "    return np.Series with corrected texts\n",
    "    \"\"\"\n",
    "    resulttext=raw_texts.str.lower()\n",
    "    for [co,naco] in replacements.values:\n",
    "       resulttext=resulttext.str.replace(re.compile(str(co)),str(naco))\n",
    "    return resulttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_texts=preprocess_texts(input_data['content'],podmiany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(prep_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_texts.to_csv(os.path.join(datapath,'texts_for_emb.txt'))\n",
    "# incorrect <- validation set użyty do nauki - trzeba poprawić\n",
    "# prep_texts.to_csv(os.path.join(datapath,'texts_for_emb.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(raw_labels,interesting_labels):\n",
    "    \"\"\"\n",
    "    raw_labels: np.Series with labels\n",
    "    interesting_labels: list of labels you are interested in\n",
    "    \n",
    "    returns np.Series with corrected labels\n",
    "    \"\"\"\n",
    "    other_label='OTHER'\n",
    "    result_labels=raw_labels\n",
    "    result_labels=result_labels.apply(lambda x: x if x in interesting_labels else other_label)\n",
    "    return result_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_categories=['XDR','XOA','XRF','XSP']\n",
    "prep_labels=preprocess_labels(input_data['category'],interesting_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prep_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(labels,dictionary=None):\n",
    "    if dictionary==None:\n",
    "        cat_labels, uniques = pd.factorize(labels)\n",
    "    else:\n",
    "        None # dorobić mapowania jeśli słownik już był podany\n",
    "    return cat_labels, uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels,label_dict=categorize_labels(prep_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(cat_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary to the disk\n",
    "pd.DataFrame(label_dict).to_excel(os.path.join(datapath,'slownik_kategorii.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data to train and validation parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train,texts_val,y_train,y_val=train_test_split(prep_texts.values,\n",
    "                                                     cat_labels,test_size=0.25,random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file for fasttext\n",
    "pd.Series(texts_train).to_csv(os.path.join(datapath,'texts_for_emb.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling to boost minority classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "texts_train, y_train = ros.fit_resample(np.reshape(texts_train, (-1, 1)),y_train)\n",
    "\n",
    "# shuffle to be sure \n",
    "texts_train, y_train = shuffle(texts_train, y_train, random_state=0)\n",
    "\n",
    "texts_train=texts_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare files for fasstext\n",
    "fasttext_train_set=[]\n",
    "for i,t in enumerate(y_train):\n",
    "    fasttext_train_set.append('__label__'+str(t)+' '+texts_train[i])\n",
    "\n",
    "fasttext_val_set=texts_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(fasttext_train_set).to_csv(os.path.join(datapath,'fasttext_train_set.txt'),sep='\\n',index=False)\n",
    "pd.Series(fasttext_val_set).to_csv(os.path.join(datapath,'fasttext_val_set.txt'),sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz odpalamy fasttext i w wyniku otrzymujemy predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted=pd.read_csv(os.path.join(datapath,'predictions.txt'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fasttext_label = lambda x: int(re.sub('__label__','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted=y_val_predicted.applymap(drop_fasttext_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred=y_val_predicted.values\n",
    "#print(y_val_predicted)\n",
    "print(y_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling also validation set \n",
    "#texts_val, y_val = ros.fit_resample(np.reshape(texts_val, (-1, 1)),y_val)\n",
    "#texts_val=texts_val.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(texts_train.shape)\n",
    "print(y_train.shape)\n",
    "print(texts_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling to boost minority classes\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "# x_train, y_train = ros.fit_resample(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate statistics per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = mymodel.predict(x_val) \n",
    "#y_preds = y_prob.argmax(axis=-1)\n",
    "y_preds = y_val_pred\n",
    "cm = metrics.confusion_matrix(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(list(y_val),list(y_preds),labels=[1,2,3,4],target_names=label_dict[1:]))\n",
    "#print(metrics.classification_report(list(y_val),list(y_preds),target_names=label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, label_dict, label_dict)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.0)#for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_val).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mymodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = mymodel.predict(x_train) \n",
    "y_preds_train = y_prob_train.argmax(axis=-1)\n",
    "cm_train = metrics.confusion_matrix(y_train, y_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_train = pd.DataFrame(cm_train, label_dict, label_dict)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.0)#for label size\n",
    "sn.heatmap(df_cm_train, annot=True, annot_kws={\"size\": 12})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(list(y_train),list(y_preds_train),labels=[1,2,3,4],target_names=label_dict[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ngram_model(data):\n",
    "    \"\"\"Tunes n-gram model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data: tuples of training and test texts and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select parameter values to try.\n",
    "    num_layers = [1, 2, 3]\n",
    "    num_units = [4, 6, 10]\n",
    "    #dropouts =[0.3,0.4,0.5]\n",
    "\n",
    "    # Save parameter combination and results.\n",
    "    params = {\n",
    "        'layers': [],\n",
    "        'units': [],\n",
    "        'accuracy': [],\n",
    "        'loss':[],\n",
    "        'f1':[],\n",
    "    }\n",
    "    \n",
    "    (x_train, y_train), (x_val, y_val) = data\n",
    "\n",
    "    # Iterate over all parameter combinations.\n",
    "    for layers in num_layers:\n",
    "        for units in num_units:\n",
    "                params['layers'].append(layers)\n",
    "                params['units'].append(units)\n",
    "                print(f'parameters: layers-{layers}, units-{units}')\n",
    "                myaccuracy, myloss, mymodel = train_ngram_model(data,\n",
    "                      num_classes=len(label_dict),\n",
    "                      learning_rate=4e-3,\n",
    "                      epochs=7,\n",
    "                      batch_size=128,\n",
    "                      layers=layers,\n",
    "                      units=units,\n",
    "                      dropout_rate=0.4,\n",
    "                      l2=0.005)\n",
    "                y_prob = mymodel.predict(x_val) \n",
    "                y_preds = y_prob.argmax(axis=-1)\n",
    "                myf1=metrics.f1_score(list(y_val),list(y_preds),labels=[1,2,3,4])\n",
    "                print((f'Accuracy: {myaccuracy}, Loss: {myloss}, F1: {myf1}, Parameters: (layers={layers}, units={units})'))\n",
    "                params['accuracy'].append(myaccuracy)\n",
    "                params['loss'].append(myloss)\n",
    "                params['f1'].append(myf1)\n",
    "    #_plot_parameters(params)\n",
    "    return params\n",
    "    \n",
    "def _plot_parameters(params):\n",
    "    \"\"\"Creates a 3D surface plot of given parameters.\n",
    "\n",
    "    # Arguments\n",
    "        params: dict, contains layers, units and accuracy value combinations.\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_trisurf(params['layers'],\n",
    "                    params['units'],\n",
    "                    params['accuracy'],\n",
    "                    cmap=cm.coolwarm,\n",
    "                    antialiased=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki = tune_ngram_model(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
